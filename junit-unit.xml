<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="40" skipped="11" tests="347" time="3.436" timestamp="2025-06-02T18:51:59.054424-04:00" hostname="Ramseys-MacBook-Pro.local"><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_power_management_config_defaults" time="0.031" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_power_management_generator_init" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_power_declarations_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_power_state_machine_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_link_state_machine_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_clock_gating_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPowerManagementGenerator" name="test_disabled_features" time="0.001" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_handling_config_defaults" time="0.001" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_declarations_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_detection_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_state_machine_generation" time="0.003" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_logging_generation" time="0.004" /><testcase classname="tests.test_advanced_sv.TestErrorHandlingGenerator" name="test_error_injection_generation" time="0.003" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_perf_counter_config_defaults" time="0.001" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_perf_declarations_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_transaction_counters_generation" time="0.005" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_bandwidth_monitoring_generation" time="0.003" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_device_specific_counters" time="0.003" /><testcase classname="tests.test_advanced_sv.TestPerformanceCounterGenerator" name="test_performance_grading_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_advanced_sv_generator_init" time="0.003" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_module_header_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_device_specific_ports" time="0.003" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_register_logic_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_register_logic_with_variance" time="0.003" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_read_logic_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_interrupt_logic_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_complete_systemverilog_generation" time="0.001" /><testcase classname="tests.test_advanced_sv.TestAdvancedSVGenerator" name="test_systemverilog_with_all_features" time="0.001" /><testcase classname="tests.test_advanced_sv.TestIntegration" name="test_file_generation" time="0.002" /><testcase classname="tests.test_advanced_sv.TestIntegration" name="test_variance_integration" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestDataClasses" name="test_register_access_creation" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestDataClasses" name="test_register_access_optional_fields" time="0.002" /><testcase classname="tests.test_behavior_profiler.TestDataClasses" name="test_timing_pattern_creation" time="0.002" /><testcase classname="tests.test_behavior_profiler.TestDataClasses" name="test_behavior_profile_creation" time="0.005" /><testcase classname="tests.test_behavior_profiler.TestBehaviorProfilerInitialization" name="test_valid_bdf_initialization" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestBehaviorProfilerInitialization" name="test_invalid_bdf_initialization" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestBehaviorProfilerInitialization" name="test_default_parameters" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestLogging" name="test_debug_logging_enabled" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestLogging" name="test_debug_logging_disabled" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestMonitoringSetup" name="test_setup_monitoring_success" time="0.003" /><testcase classname="tests.test_behavior_profiler.TestMonitoringSetup" name="test_setup_monitoring_device_not_found" time="0.006" /><testcase classname="tests.test_behavior_profiler.TestMonitoringSetup" name="test_setup_monitoring_command_failure" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestBehaviorCapture" name="test_capture_behavior_profile_success" time="0.001"><failure message="AttributeError: &lt;class 'behavior_profiler.BehaviorProfiler'&gt; does not have the attribute '_stop_monitoring'">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1421: in patched
    with self.decoration_helper(patched,
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141: in __enter__
    return next(self.gen)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1403: in decoration_helper
    arg = exit_stack.enter_context(patching)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:530: in enter_context
    result = _enter(cm)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1495: in __enter__
    original, local = self.get_original()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: &lt;class 'behavior_profiler.BehaviorProfiler'&gt; does not have the attribute '_stop_monitoring'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestBehaviorCapture" name="test_capture_behavior_profile_setup_failure" time="0.002"><failure message="AssertionError: Regex pattern did not match.&#10; Regex: 'Failed to setup monitoring'&#10; Input: 'Failed to start monitoring'">tests/test_behavior_profiler.py:237: in test_capture_behavior_profile_setup_failure
    profiler.capture_behavior_profile(1.0)
src/behavior_profiler.py:370: in capture_behavior_profile
    raise RuntimeError("Failed to start monitoring")
E   RuntimeError: Failed to start monitoring

During handling of the above exception, another exception occurred:
tests/test_behavior_profiler.py:236: in test_capture_behavior_profile_setup_failure
    with pytest.raises(RuntimeError, match="Failed to setup monitoring"):
E   AssertionError: Regex pattern did not match.
E    Regex: 'Failed to setup monitoring'
E    Input: 'Failed to start monitoring'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestBehaviorCapture" name="test_capture_behavior_profile_with_duration" time="0.001"><failure message="AttributeError: &lt;class 'behavior_profiler.BehaviorProfiler'&gt; does not have the attribute '_stop_monitoring'">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1421: in patched
    with self.decoration_helper(patched,
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141: in __enter__
    return next(self.gen)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1403: in decoration_helper
    arg = exit_stack.enter_context(patching)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:530: in enter_context
    result = _enter(cm)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1495: in __enter__
    original, local = self.get_original()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: &lt;class 'behavior_profiler.BehaviorProfiler'&gt; does not have the attribute '_stop_monitoring'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestPatternAnalysis" name="test_analyze_patterns_basic" time="0.002"><failure message="AssertionError: assert 'register_usage' in {'behavioral_signatures': {'interrupt_activity': 0, 'state_complexity': 1, 'timing_regularity': 0.95}, 'device_characteristics': {'access_frequency_hz': 0.4, 'most_active_registers': [('REG_CTRL', 3), ('REG_STATUS', 1)], 'read_write_ratio': 0.3333333333333333, 'total_registers_accessed': 2}, 'performance_metrics': {'avg_access_duration_us': 4.5, 'max_access_duration_us': 5.5, 'min_access_duration_us': 3.0}, 'recommendations': ['Low-frequency device - simple polling model may suffice', 'Highly regular timing patterns - implement precise timing simulation'], ...}">tests/test_behavior_profiler.py:292: in test_analyze_patterns_basic
    assert "register_usage" in analysis
E   AssertionError: assert 'register_usage' in {'behavioral_signatures': {'interrupt_activity': 0, 'state_complexity': 1, 'timing_regularity': 0.95}, 'device_characteristics': {'access_frequency_hz': 0.4, 'most_active_registers': [('REG_CTRL', 3), ('REG_STATUS', 1)], 'read_write_ratio': 0.3333333333333333, 'total_registers_accessed': 2}, 'performance_metrics': {'avg_access_duration_us': 4.5, 'max_access_duration_us': 5.5, 'min_access_duration_us': 3.0}, 'recommendations': ['Low-frequency device - simple polling model may suffice', 'Highly regular timing patterns - implement precise timing simulation'], ...}</failure></testcase><testcase classname="tests.test_behavior_profiler.TestPatternAnalysis" name="test_analyze_patterns_empty_profile" time="0.002"><failure message="KeyError: 'register_diversity'">tests/test_behavior_profiler.py:324: in test_analyze_patterns_empty_profile
    assert analysis["device_characteristics"]["register_diversity"] == 0
E   KeyError: 'register_diversity'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestPatternAnalysis" name="test_analyze_patterns_single_register" time="0.001"><failure message="KeyError: 'register_diversity'">tests/test_behavior_profiler.py:345: in test_analyze_patterns_single_register
    assert analysis["device_characteristics"]["register_diversity"] == 1
E   KeyError: 'register_diversity'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestTimingPatternDetection" name="test_detect_periodic_patterns" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?">tests/test_behavior_profiler.py:369: in test_detect_periodic_patterns
    patterns = profiler._detect_timing_patterns(accesses)
E   AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestTimingPatternDetection" name="test_detect_burst_patterns" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?">tests/test_behavior_profiler.py:413: in test_detect_burst_patterns
    patterns = profiler._detect_timing_patterns(accesses)
E   AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestTimingPatternDetection" name="test_detect_irregular_patterns" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?">tests/test_behavior_profiler.py:438: in test_detect_irregular_patterns
    patterns = profiler._detect_timing_patterns(accesses)
E   AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestStateTransitionAnalysis" name="test_analyze_state_transitions_simple" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestStateTransitionAnalysis" name="test_analyze_state_transitions_empty" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestInterruptPatternAnalysis" name="test_analyze_interrupt_patterns_success" time="0.001"><failure message="TypeError: BehaviorProfiler._analyze_interrupt_patterns() missing 1 required positional argument: 'accesses'">tests/test_behavior_profiler.py:491: in test_analyze_interrupt_patterns_success
    patterns = profiler._analyze_interrupt_patterns()
E   TypeError: BehaviorProfiler._analyze_interrupt_patterns() missing 1 required positional argument: 'accesses'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestInterruptPatternAnalysis" name="test_analyze_interrupt_patterns_failure" time="0.001"><failure message="TypeError: BehaviorProfiler._analyze_interrupt_patterns() missing 1 required positional argument: 'accesses'">tests/test_behavior_profiler.py:502: in test_analyze_interrupt_patterns_failure
    patterns = profiler._analyze_interrupt_patterns()
E   TypeError: BehaviorProfiler._analyze_interrupt_patterns() missing 1 required positional argument: 'accesses'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestMonitoringThreads" name="test_start_stop_monitoring" time="0.001"><failure message="AttributeError: &lt;behavior_profiler.BehaviorProfiler object at 0x1040c1180&gt; does not have the attribute '_monitor_device_access'">tests/test_behavior_profiler.py:515: in test_start_stop_monitoring
    with patch.object(profiler, "_monitor_device_access") as mock_monitor:
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1495: in __enter__
    original, local = self.get_original()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: &lt;behavior_profiler.BehaviorProfiler object at 0x1040c1180&gt; does not have the attribute '_monitor_device_access'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestMonitoringThreads" name="test_monitor_device_access_mock" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestErrorHandling" name="test_invalid_duration" time="0.006"><failure message="RuntimeError: Failed to start monitoring">tests/test_behavior_profiler.py:560: in test_invalid_duration
    profiler.capture_behavior_profile(-1.0)
src/behavior_profiler.py:370: in capture_behavior_profile
    raise RuntimeError("Failed to start monitoring")
E   RuntimeError: Failed to start monitoring</failure></testcase><testcase classname="tests.test_behavior_profiler.TestErrorHandling" name="test_monitoring_already_active" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_start_monitoring'. Did you mean: 'start_monitoring'?">tests/test_behavior_profiler.py:571: in test_monitoring_already_active
    profiler._start_monitoring()
E   AttributeError: 'BehaviorProfiler' object has no attribute '_start_monitoring'. Did you mean: 'start_monitoring'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestErrorHandling" name="test_stop_monitoring_not_active" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_stop_monitoring'. Did you mean: 'stop_monitoring'?">tests/test_behavior_profiler.py:578: in test_stop_monitoring_not_active
    profiler._stop_monitoring()
E   AttributeError: 'BehaviorProfiler' object has no attribute '_stop_monitoring'. Did you mean: 'stop_monitoring'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestErrorHandling" name="test_queue_overflow_handling" time="0.003" /><testcase classname="tests.test_behavior_profiler.TestPerformanceCharacteristics" name="test_large_dataset_analysis_performance" time="0.007"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?">tests/test_behavior_profiler.py:625: in test_large_dataset_analysis_performance
    patterns = profiler._detect_timing_patterns(accesses)
E   AttributeError: 'BehaviorProfiler' object has no attribute '_detect_timing_patterns'. Did you mean: '_analyze_timing_patterns'?</failure></testcase><testcase classname="tests.test_behavior_profiler.TestPerformanceCharacteristics" name="test_memory_usage_optimization" time="0.091" /><testcase classname="tests.test_behavior_profiler.TestIntegrationWithBuildSystem" name="test_profile_data_serialization" time="0.001" /><testcase classname="tests.test_behavior_profiler.TestIntegrationWithBuildSystem" name="test_enhanced_register_context_generation" time="0.001"><failure message="AttributeError: 'BehaviorProfiler' object has no attribute '_generate_enhanced_context'">tests/test_behavior_profiler.py:698: in test_enhanced_register_context_generation
    enhanced_context = profiler._generate_enhanced_context(mock_behavior_profile)
E   AttributeError: 'BehaviorProfiler' object has no attribute '_generate_enhanced_context'</failure></testcase><testcase classname="tests.test_behavior_profiler.TestIntegrationWithBuildSystem" name="test_build_system_compatibility" time="0.001" /><testcase classname="tests.test_build.TestSecurityAndTempFiles" name="test_create_secure_tempfile_success" time="0.002" /><testcase classname="tests.test_build.TestSecurityAndTempFiles" name="test_create_secure_tempfile_error_cleanup" time="0.001"><failure message="Failed: DID NOT RAISE &lt;class 'OSError'&gt;">tests/test_build.py:53: in test_create_secure_tempfile_error_cleanup
    with pytest.raises(OSError):
E   Failed: DID NOT RAISE &lt;class 'OSError'&gt;</failure></testcase><testcase classname="tests.test_build.TestDonorInfoExtraction" name="test_get_donor_info_success" time="0.001" /><testcase classname="tests.test_build.TestDonorInfoExtraction" name="test_get_donor_info_missing_fields" time="0.001" /><testcase classname="tests.test_build.TestDonorInfoExtraction" name="test_get_donor_info_malformed_output" time="0.001" /><testcase classname="tests.test_build.TestDriverRegisterScraping" name="test_scrape_driver_regs_success" time="0.001" /><testcase classname="tests.test_build.TestDriverRegisterScraping" name="test_scrape_driver_regs_command_failure" time="0.001" /><testcase classname="tests.test_build.TestDriverRegisterScraping" name="test_scrape_driver_regs_invalid_json" time="0.001" /><testcase classname="tests.test_build.TestBehaviorProfiling" name="test_integrate_behavior_profile_success" time="0.001" /><testcase classname="tests.test_build.TestBehaviorProfiling" name="test_integrate_behavior_profile_import_error" time="0.001" /><testcase classname="tests.test_build.TestBehaviorProfiling" name="test_integrate_behavior_profile_profiling_error" time="0.001" /><testcase classname="tests.test_build.TestSystemVerilogGeneration" name="test_build_sv_success" time="0.002" /><testcase classname="tests.test_build.TestSystemVerilogGeneration" name="test_build_sv_no_registers" time="0.001" /><testcase classname="tests.test_build.TestSystemVerilogGeneration" name="test_build_sv_complex_timing" time="0.002" /><testcase classname="tests.test_build.TestStateMachineGeneration" name="test_generate_register_state_machine_simple" time="0.001" /><testcase classname="tests.test_build.TestStateMachineGeneration" name="test_generate_register_state_machine_insufficient_sequences" time="0.001" /><testcase classname="tests.test_build.TestStateMachineGeneration" name="test_generate_device_state_machine" time="0.001" /><testcase classname="tests.test_build.TestStateMachineGeneration" name="test_generate_device_state_machine_empty_regs" time="0.001" /><testcase classname="tests.test_build.TestTCLGeneration" name="test_code_from_bytes_valid" time="0.001" /><testcase classname="tests.test_build.TestTCLGeneration" name="test_code_from_bytes_invalid" time="0.001" /><testcase classname="tests.test_build.TestTCLGeneration" name="test_build_tcl_success" time="0.001" /><testcase classname="tests.test_build.TestTCLGeneration" name="test_build_tcl_unsupported_bar_size" time="0.001" /><testcase classname="tests.test_build.TestBoardConfiguration" name="test_board_info_constants" time="0.001" /><testcase classname="tests.test_build.TestBoardConfiguration" name="test_aperture_constants" time="0.001" /><testcase classname="tests.test_build.TestUtilityFunctions" name="test_run_command_success" time="0.001" /><testcase classname="tests.test_build.TestUtilityFunctions" name="test_run_command_failure" time="0.001" /><testcase classname="tests.test_build.TestIntegrationScenarios" name="test_full_build_workflow" time="0.001" /><testcase classname="tests.test_build.TestErrorHandlingAndEdgeCases" name="test_empty_register_list_handling" time="0.001" /><testcase classname="tests.test_build.TestErrorHandlingAndEdgeCases" name="test_malformed_register_data" time="0.001" /><testcase classname="tests.test_build.TestErrorHandlingAndEdgeCases" name="test_missing_context_data" time="0.001" /><testcase classname="tests.test_build.TestPerformanceAndScaling" name="test_large_register_set_generation" time="0.009" /><testcase classname="tests.test_build.TestPerformanceAndScaling" name="test_memory_usage_with_large_datasets" time="0.002" /><testcase classname="tests.test_build.TestRegressionPrevention" name="test_register_offset_formatting" time="0.001" /><testcase classname="tests.test_build.TestRegressionPrevention" name="test_special_character_handling_in_names" time="0.002" /><testcase classname="tests.test_build.TestRegressionPrevention" name="test_timing_calculation_edge_cases" time="0.001" /><testcase classname="tests.test_build_integration.TestBuildWithExternalExamples" name="test_build_sv_with_example_registers" time="0.003" /><testcase classname="tests.test_build_integration.TestBuildWithExternalExamples" name="test_build_tcl_with_example_donor_info" time="0.001" /><testcase classname="tests.test_build_integration.TestBuildWithExternalExamples" name="test_full_build_workflow_with_example_data" time="0.002" /><testcase classname="tests.test_build_integration.TestAdvancedSVWithExternalExamples" name="test_advanced_sv_with_example_registers" time="0.002" /><testcase classname="tests.test_build_integration.TestAdvancedSVWithExternalExamples" name="test_variance_model_with_example_registers" time="0.002" /><testcase classname="tests.test_build_integration.TestBuildScriptIntegration" name="test_build_script_with_example_files" time="0.003"><skipped type="pytest.skip" message="build_fpga function not found">/Users/ramseymcgrath/code/PCILeechFWGenerator/tests/test_build_integration.py:458: build_fpga function not found</skipped></testcase><testcase classname="tests.test_build_integration.TestBuildScriptIntegration" name="test_tcl_script_execution_with_example" time="0.002" /><testcase classname="tests.test_donor_dump.TestKernelModuleBuild" name="test_module_compilation_success" time="0.001"><failure message="AttributeError: type object 'Mock' has no attribute 'call'. Did you mean: 'called'?">tests/test_donor_dump.py:37: in test_module_compilation_success
    Mock.call("make clean", shell=True, check=True),
E   AttributeError: type object 'Mock' has no attribute 'call'. Did you mean: 'called'?</failure></testcase><testcase classname="tests.test_donor_dump.TestKernelModuleBuild" name="test_module_compilation_failure" time="0.001" /><testcase classname="tests.test_donor_dump.TestKernelModuleBuild" name="test_kernel_headers_check" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleParameters" name="test_bdf_parameter_validation" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleParameters" name="test_module_parameter_parsing" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleLoading" name="test_module_loading_success" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleLoading" name="test_module_loading_failure" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleLoading" name="test_module_unloading" time="0.001" /><testcase classname="tests.test_donor_dump.TestModuleLoading" name="test_module_already_loaded_handling" time="0.001" /><testcase classname="tests.test_donor_dump.TestProcInterface" name="test_proc_donor_dump_output_parsing" time="0.001" /><testcase classname="tests.test_donor_dump.TestProcInterface" name="test_proc_output_missing_fields" time="0.001" /><testcase classname="tests.test_donor_dump.TestProcInterface" name="test_proc_output_malformed" time="0.001" /><testcase classname="tests.test_donor_dump.TestDeviceAccess" name="test_pci_config_space_access_simulation" time="0.001" /><testcase classname="tests.test_donor_dump.TestDeviceAccess" name="test_bar_size_calculation" time="0.001" /><testcase classname="tests.test_donor_dump.TestDeviceAccess" name="test_extended_config_space_access" time="0.001" /><testcase classname="tests.test_donor_dump.TestErrorHandling" name="test_device_not_found_error" time="0.001" /><testcase classname="tests.test_donor_dump.TestErrorHandling" name="test_permission_denied_error" time="0.001" /><testcase classname="tests.test_donor_dump.TestErrorHandling" name="test_module_build_dependency_missing" time="0.001" /><testcase classname="tests.test_donor_dump.TestErrorHandling" name="test_invalid_bdf_parameter_handling" time="0.001" /><testcase classname="tests.test_donor_dump.TestHardwareSimulation" name="test_simulated_pci_device_data" time="0.001" /><testcase classname="tests.test_donor_dump.TestHardwareSimulation" name="test_simulated_config_space_data" time="0.001" /><testcase classname="tests.test_donor_dump.TestMakefileValidation" name="test_makefile_exists" time="0.001" /><testcase classname="tests.test_donor_dump.TestMakefileValidation" name="test_makefile_targets" time="0.002" /><testcase classname="tests.test_donor_dump.TestMakefileValidation" name="test_kernel_version_compatibility" time="0.001" /><testcase classname="tests.test_driver_scrape.TestHelperFunctions" name="test_run_command_success" time="0.001" /><testcase classname="tests.test_driver_scrape.TestHelperFunctions" name="test_run_command_failure" time="0.001" /><testcase classname="tests.test_driver_scrape.TestKernelSourceManagement" name="test_ensure_kernel_source_extract_needed" time="0.001"><failure message="TypeError: 'list' object is not an iterator">tests/test_driver_scrape.py:67: in test_ensure_kernel_source_extract_needed
    result = driver_scrape.ensure_kernel_source()
src/scripts/driver_scrape.py:41: in ensure_kernel_source
    src_pkg = next(pathlib.Path("/usr/src").glob("linux-source-*.tar*"), None)
E   TypeError: 'list' object is not an iterator</failure></testcase><testcase classname="tests.test_driver_scrape.TestKernelSourceManagement" name="test_ensure_kernel_source_already_extracted" time="0.001"><failure message="TypeError: 'list' object is not an iterator">tests/test_driver_scrape.py:85: in test_ensure_kernel_source_already_extracted
    result = driver_scrape.ensure_kernel_source()
src/scripts/driver_scrape.py:41: in ensure_kernel_source
    src_pkg = next(pathlib.Path("/usr/src").glob("linux-source-*.tar*"), None)
E   TypeError: 'list' object is not an iterator</failure></testcase><testcase classname="tests.test_driver_scrape.TestKernelSourceManagement" name="test_ensure_kernel_source_not_found" time="0.001"><failure message="TypeError: 'list' object is not an iterator">tests/test_driver_scrape.py:95: in test_ensure_kernel_source_not_found
    driver_scrape.ensure_kernel_source()
src/scripts/driver_scrape.py:41: in ensure_kernel_source
    src_pkg = next(pathlib.Path("/usr/src").glob("linux-source-*.tar*"), None)
E   TypeError: 'list' object is not an iterator</failure></testcase><testcase classname="tests.test_driver_scrape.TestModuleResolution" name="test_ko_name_from_alias_success" time="0.001" /><testcase classname="tests.test_driver_scrape.TestModuleResolution" name="test_ko_name_from_alias_not_found" time="0.001" /><testcase classname="tests.test_driver_scrape.TestFunctionContextAnalysis" name="test_analyze_function_context_complete" time="0.002" /><testcase classname="tests.test_driver_scrape.TestFunctionContextAnalysis" name="test_analyze_function_context_interrupt_handler" time="0.002" /><testcase classname="tests.test_driver_scrape.TestFunctionContextAnalysis" name="test_analyze_function_context_runtime_function" time="0.002" /><testcase classname="tests.test_driver_scrape.TestFunctionContextAnalysis" name="test_analyze_function_context_not_found" time="0.001" /><testcase classname="tests.test_driver_scrape.TestFunctionContextAnalysis" name="test_analyze_function_context_cleanup_function" time="0.002" /><testcase classname="tests.test_driver_scrape.TestAccessPatternAnalysis" name="test_access_pattern_write_heavy" time="0.002"><failure message="AssertionError: assert 'read_write' == 'write_heavy'&#10;  &#10;  - write_heavy&#10;  + read_write">tests/test_driver_scrape.py:245: in test_access_pattern_write_heavy
    assert context["access_pattern"] == "write_heavy"
E   AssertionError: assert 'read_write' == 'write_heavy'
E     
E     - write_heavy
E     + read_write</failure></testcase><testcase classname="tests.test_driver_scrape.TestAccessPatternAnalysis" name="test_access_pattern_read_heavy" time="0.002"><failure message="AssertionError: assert 'read_write' == 'read_heavy'&#10;  &#10;  - read_heavy&#10;  + read_write">tests/test_driver_scrape.py:261: in test_access_pattern_read_heavy
    assert context["access_pattern"] == "read_heavy"
E   AssertionError: assert 'read_write' == 'read_heavy'
E     
E     - read_heavy
E     + read_write</failure></testcase><testcase classname="tests.test_driver_scrape.TestAccessPatternAnalysis" name="test_access_pattern_balanced" time="0.002"><failure message="AssertionError: assert 'read_write' == 'balanced'&#10;  &#10;  - balanced&#10;  + read_write">tests/test_driver_scrape.py:275: in test_access_pattern_balanced
    assert context["access_pattern"] == "balanced"
E   AssertionError: assert 'read_write' == 'balanced'
E     
E     - balanced
E     + read_write</failure></testcase><testcase classname="tests.test_driver_scrape.TestAccessPatternAnalysis" name="test_access_pattern_write_then_read" time="0.002"><failure message="AssertionError: assert 'read_write' == 'write_then_read'&#10;  &#10;  - write_then_read&#10;  + read_write">tests/test_driver_scrape.py:287: in test_access_pattern_write_then_read
    assert context["access_pattern"] == "write_then_read"
E   AssertionError: assert 'read_write' == 'write_then_read'
E     
E     - write_then_read
E     + read_write</failure></testcase><testcase classname="tests.test_driver_scrape.TestTimingConstraintAnalysis" name="test_analyze_timing_constraints_with_delays" time="0.002" /><testcase classname="tests.test_driver_scrape.TestTimingConstraintAnalysis" name="test_analyze_timing_constraints_no_delays" time="0.001" /><testcase classname="tests.test_driver_scrape.TestTimingConstraintAnalysis" name="test_analyze_timing_constraints_complex_delays" time="0.001" /><testcase classname="tests.test_driver_scrape.TestSequenceAnalysis" name="test_analyze_access_sequences_simple" time="0.002" /><testcase classname="tests.test_driver_scrape.TestSequenceAnalysis" name="test_analyze_access_sequences_multiple_functions" time="0.001" /><testcase classname="tests.test_driver_scrape.TestSequenceAnalysis" name="test_analyze_access_sequences_complex_function" time="0.001" /><testcase classname="tests.test_driver_scrape.TestRegisterExtraction" name="test_extract_registers_from_header" time="0.002" /><testcase classname="tests.test_driver_scrape.TestRegisterExtraction" name="test_extract_registers_from_source" time="0.005" /><testcase classname="tests.test_driver_scrape.TestMainWorkflow" name="test_main_workflow_success" time="0.001"><failure message="AttributeError: &lt;module 'driver_scrape' from '/Users/ramseymcgrath/code/PCILeechFWGenerator/src/scripts/driver_scrape.py'&gt; does not have the attribute 'extract_and_analyze_registers'">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1421: in patched
    with self.decoration_helper(patched,
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141: in __enter__
    return next(self.gen)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1403: in decoration_helper
    arg = exit_stack.enter_context(patching)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:530: in enter_context
    result = _enter(cm)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1495: in __enter__
    original, local = self.get_original()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1465: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'driver_scrape' from '/Users/ramseymcgrath/code/PCILeechFWGenerator/src/scripts/driver_scrape.py'&gt; does not have the attribute 'extract_and_analyze_registers'</failure></testcase><testcase classname="tests.test_driver_scrape.TestErrorHandling" name="test_invalid_vendor_device_format" time="0.001" /><testcase classname="tests.test_driver_scrape.TestErrorHandling" name="test_file_not_found_handling" time="0.001" /><testcase classname="tests.test_driver_scrape.TestErrorHandling" name="test_malformed_register_definitions" time="0.001" /><testcase classname="tests.test_driver_scrape.TestErrorHandling" name="test_empty_source_files" time="0.002" /><testcase classname="tests.test_driver_scrape.TestErrorHandling" name="test_binary_file_handling" time="0.001" /><testcase classname="tests.test_driver_scrape.TestPerformanceAndScaling" name="test_large_source_file_processing" time="0.003" /><testcase classname="tests.test_driver_scrape.TestPerformanceAndScaling" name="test_memory_usage_with_large_datasets" time="0.033" /><testcase classname="tests.test_driver_scrape.TestOutputFormatting" name="test_json_output_format" time="0.001" /><testcase classname="tests.test_driver_scrape.TestOutputFormatting" name="test_json_output_special_characters" time="0.001" /><testcase classname="tests.test_driver_scrape.TestOutputFormatting" name="test_empty_output_handling" time="0.001" /><testcase classname="tests.test_external_integration.TestExternalPatternIntegration" name="test_advanced_sv_generator_with_external_patterns" time="0.003" /><testcase classname="tests.test_external_integration.TestExternalPatternIntegration" name="test_power_management_with_external_patterns" time="0.001" /><testcase classname="tests.test_external_integration.TestExternalPatternIntegration" name="test_error_handling_with_external_patterns" time="0.001" /><testcase classname="tests.test_external_integration.TestExternalPatternIntegration" name="test_performance_counters_with_external_patterns" time="0.001" /><testcase classname="tests.test_external_integration.TestExternalExampleBasedRegisters" name="test_extract_registers_from_example" time="0.004"><failure message="AssertionError: Register pcileech_com_status doesn't have correct value&#10;assert (&quot;32'h1&quot; in '//==============================================================================\n// Advanced PCIe Device Controller with Comprehensive Features\n// Generated by AdvancedSVGenerator - Advanced SystemVerilog Generation Feature\n//\n// Features:\n// - Advanced power management (D0-D3, L0-L3 states)\n// - Comprehensive error handling and recovery\n// - Hardware performance counters\n// - Multiple clock domain support\n// - Device-specific optimizations (generic)\n// - Manufacturing variance integration\n//==============================================================================\n\n// State machine definitions\n`define S_SHADOW_CFGSPACE_IDLE  2\'b00\n`define S_SHADOW_CFGSPACE_TLP   2\'b01\n`define S_SHADOW_CFGSPACE_USB   2\'b10\n\nmodule advanced_pcileech_controller #(\n    parameter DEVICE_TYPE = &quot;generic&quot;,\n    parameter DEVICE_CLASS = &quot;consumer&quot;,\n    parameter MAX_PAYLOAD_SIZE = 256,\n    parameter MSI_VECTORS = 1,\n    parameter COUNTER_WIDTH = 32\n) (\n    // Clock and reset\n    input logic clk,\n    input logic reset_n,\n    \n    // Additional clock domains\n    input logic mem_clk,\n    input logic aux_clk,\n    \n    // PCIe interface\n    input logic [31:0] bar_addr...c src_valid,\n    output logic src_ready,\n    output logic [DATA_WIDTH-1:0] dst_data,\n    output logic dst_valid,\n    input logic dst_ready\n);\n\n    // Implementation of advanced clock domain crossing with variance compensation\n    logic [SYNC_STAGES-1:0] sync_reg;\n    logic [DATA_WIDTH-1:0] data_reg;\n    logic valid_reg;\n    \n    // Source domain logic\n    always_ff @(posedge src_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            data_reg &lt;= \'0;\n            valid_reg &lt;= 1\'b0;\n        end else if (src_valid &amp;&amp; src_ready) begin\n            data_reg &lt;= src_data;\n            valid_reg &lt;= 1\'b1;\n        end else if (sync_reg[SYNC_STAGES-1]) begin\n            valid_reg &lt;= 1\'b0;\n        end\n    end\n    \n    // Destination domain synchronizer\n    always_ff @(posedge dst_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            sync_reg &lt;= \'0;\n        end else begin\n            sync_reg &lt;= {sync_reg[SYNC_STAGES-2:0], valid_reg};\n        end\n    end\n    \n    assign src_ready = !valid_reg || sync_reg[SYNC_STAGES-1];\n    assign dst_data = data_reg;\n    assign dst_valid = sync_reg[SYNC_STAGES-1] &amp;&amp; dst_ready;\n\nendmodule\n' or &quot;32'h01&quot; in '//==============================================================================\n// Advanced PCIe Device Controller with Comprehensive Features\n// Generated by AdvancedSVGenerator - Advanced SystemVerilog Generation Feature\n//\n// Features:\n// - Advanced power management (D0-D3, L0-L3 states)\n// - Comprehensive error handling and recovery\n// - Hardware performance counters\n// - Multiple clock domain support\n// - Device-specific optimizations (generic)\n// - Manufacturing variance integration\n//==============================================================================\n\n// State machine definitions\n`define S_SHADOW_CFGSPACE_IDLE  2\'b00\n`define S_SHADOW_CFGSPACE_TLP   2\'b01\n`define S_SHADOW_CFGSPACE_USB   2\'b10\n\nmodule advanced_pcileech_controller #(\n    parameter DEVICE_TYPE = &quot;generic&quot;,\n    parameter DEVICE_CLASS = &quot;consumer&quot;,\n    parameter MAX_PAYLOAD_SIZE = 256,\n    parameter MSI_VECTORS = 1,\n    parameter COUNTER_WIDTH = 32\n) (\n    // Clock and reset\n    input logic clk,\n    input logic reset_n,\n    \n    // Additional clock domains\n    input logic mem_clk,\n    input logic aux_clk,\n    \n    // PCIe interface\n    input logic [31:0] bar_addr...c src_valid,\n    output logic src_ready,\n    output logic [DATA_WIDTH-1:0] dst_data,\n    output logic dst_valid,\n    input logic dst_ready\n);\n\n    // Implementation of advanced clock domain crossing with variance compensation\n    logic [SYNC_STAGES-1:0] sync_reg;\n    logic [DATA_WIDTH-1:0] data_reg;\n    logic valid_reg;\n    \n    // Source domain logic\n    always_ff @(posedge src_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            data_reg &lt;= \'0;\n            valid_reg &lt;= 1\'b0;\n        end else if (src_valid &amp;&amp; src_ready) begin\n            data_reg &lt;= src_data;\n            valid_reg &lt;= 1\'b1;\n        end else if (sync_reg[SYNC_STAGES-1]) begin\n            valid_reg &lt;= 1\'b0;\n        end\n    end\n    \n    // Destination domain synchronizer\n    always_ff @(posedge dst_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            sync_reg &lt;= \'0;\n        end else begin\n            sync_reg &lt;= {sync_reg[SYNC_STAGES-2:0], valid_reg};\n        end\n    end\n    \n    assign src_ready = !valid_reg || sync_reg[SYNC_STAGES-1];\n    assign dst_data = data_reg;\n    assign dst_valid = sync_reg[SYNC_STAGES-1] &amp;&amp; dst_ready;\n\nendmodule\n')">tests/test_external_integration.py:446: in test_extract_registers_from_example
    assert (
E   AssertionError: Register pcileech_com_status doesn't have correct value
E   assert ("32'h1" in '//==============================================================================\n// Advanced PCIe Device Controller with Comprehensive Features\n// Generated by AdvancedSVGenerator - Advanced SystemVerilog Generation Feature\n//\n// Features:\n// - Advanced power management (D0-D3, L0-L3 states)\n// - Comprehensive error handling and recovery\n// - Hardware performance counters\n// - Multiple clock domain support\n// - Device-specific optimizations (generic)\n// - Manufacturing variance integration\n//==============================================================================\n\n// State machine definitions\n`define S_SHADOW_CFGSPACE_IDLE  2\'b00\n`define S_SHADOW_CFGSPACE_TLP   2\'b01\n`define S_SHADOW_CFGSPACE_USB   2\'b10\n\nmodule advanced_pcileech_controller #(\n    parameter DEVICE_TYPE = "generic",\n    parameter DEVICE_CLASS = "consumer",\n    parameter MAX_PAYLOAD_SIZE = 256,\n    parameter MSI_VECTORS = 1,\n    parameter COUNTER_WIDTH = 32\n) (\n    // Clock and reset\n    input logic clk,\n    input logic reset_n,\n    \n    // Additional clock domains\n    input logic mem_clk,\n    input logic aux_clk,\n    \n    // PCIe interface\n    input logic [31:0] bar_addr...c src_valid,\n    output logic src_ready,\n    output logic [DATA_WIDTH-1:0] dst_data,\n    output logic dst_valid,\n    input logic dst_ready\n);\n\n    // Implementation of advanced clock domain crossing with variance compensation\n    logic [SYNC_STAGES-1:0] sync_reg;\n    logic [DATA_WIDTH-1:0] data_reg;\n    logic valid_reg;\n    \n    // Source domain logic\n    always_ff @(posedge src_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            data_reg &lt;= \'0;\n            valid_reg &lt;= 1\'b0;\n        end else if (src_valid &amp;&amp; src_ready) begin\n            data_reg &lt;= src_data;\n            valid_reg &lt;= 1\'b1;\n        end else if (sync_reg[SYNC_STAGES-1]) begin\n            valid_reg &lt;= 1\'b0;\n        end\n    end\n    \n    // Destination domain synchronizer\n    always_ff @(posedge dst_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            sync_reg &lt;= \'0;\n        end else begin\n            sync_reg &lt;= {sync_reg[SYNC_STAGES-2:0], valid_reg};\n        end\n    end\n    \n    assign src_ready = !valid_reg || sync_reg[SYNC_STAGES-1];\n    assign dst_data = data_reg;\n    assign dst_valid = sync_reg[SYNC_STAGES-1] &amp;&amp; dst_ready;\n\nendmodule\n' or "32'h01" in '//==============================================================================\n// Advanced PCIe Device Controller with Comprehensive Features\n// Generated by AdvancedSVGenerator - Advanced SystemVerilog Generation Feature\n//\n// Features:\n// - Advanced power management (D0-D3, L0-L3 states)\n// - Comprehensive error handling and recovery\n// - Hardware performance counters\n// - Multiple clock domain support\n// - Device-specific optimizations (generic)\n// - Manufacturing variance integration\n//==============================================================================\n\n// State machine definitions\n`define S_SHADOW_CFGSPACE_IDLE  2\'b00\n`define S_SHADOW_CFGSPACE_TLP   2\'b01\n`define S_SHADOW_CFGSPACE_USB   2\'b10\n\nmodule advanced_pcileech_controller #(\n    parameter DEVICE_TYPE = "generic",\n    parameter DEVICE_CLASS = "consumer",\n    parameter MAX_PAYLOAD_SIZE = 256,\n    parameter MSI_VECTORS = 1,\n    parameter COUNTER_WIDTH = 32\n) (\n    // Clock and reset\n    input logic clk,\n    input logic reset_n,\n    \n    // Additional clock domains\n    input logic mem_clk,\n    input logic aux_clk,\n    \n    // PCIe interface\n    input logic [31:0] bar_addr...c src_valid,\n    output logic src_ready,\n    output logic [DATA_WIDTH-1:0] dst_data,\n    output logic dst_valid,\n    input logic dst_ready\n);\n\n    // Implementation of advanced clock domain crossing with variance compensation\n    logic [SYNC_STAGES-1:0] sync_reg;\n    logic [DATA_WIDTH-1:0] data_reg;\n    logic valid_reg;\n    \n    // Source domain logic\n    always_ff @(posedge src_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            data_reg &lt;= \'0;\n            valid_reg &lt;= 1\'b0;\n        end else if (src_valid &amp;&amp; src_ready) begin\n            data_reg &lt;= src_data;\n            valid_reg &lt;= 1\'b1;\n        end else if (sync_reg[SYNC_STAGES-1]) begin\n            valid_reg &lt;= 1\'b0;\n        end\n    end\n    \n    // Destination domain synchronizer\n    always_ff @(posedge dst_clk or negedge reset_n) begin\n        if (!reset_n) begin\n            sync_reg &lt;= \'0;\n        end else begin\n            sync_reg &lt;= {sync_reg[SYNC_STAGES-2:0], valid_reg};\n        end\n    end\n    \n    assign src_ready = !valid_reg || sync_reg[SYNC_STAGES-1];\n    assign dst_data = data_reg;\n    assign dst_valid = sync_reg[SYNC_STAGES-1] &amp;&amp; dst_ready;\n\nendmodule\n')</failure></testcase><testcase classname="tests.test_external_integration.TestExternalExampleBasedRegisters" name="test_register_access_patterns_from_example" time="0.001" /><testcase classname="tests.test_external_integration.TestExternalExampleBasedStateMachines" name="test_extract_state_machines_from_example" time="0.002" /><testcase classname="tests.test_flash_fpga.TestCommandExecution" name="test_run_command_success" time="0.001" /><testcase classname="tests.test_flash_fpga.TestCommandExecution" name="test_run_command_failure" time="0.001" /><testcase classname="tests.test_flash_fpga.TestArgumentParsing" name="test_argument_parser_creation" time="0.001" /><testcase classname="tests.test_flash_fpga.TestArgumentParsing" name="test_argument_parser_missing_bitfile" time="0.001" /><testcase classname="tests.test_flash_fpga.TestUSBLoaderValidation" name="test_usbloader_available" time="0.001" /><testcase classname="tests.test_flash_fpga.TestUSBLoaderValidation" name="test_usbloader_not_available" time="0.001" /><testcase classname="tests.test_flash_fpga.TestBitfileValidation" name="test_bitfile_exists" time="0.001" /><testcase classname="tests.test_flash_fpga.TestBitfileValidation" name="test_bitfile_not_exists" time="0.001" /><testcase classname="tests.test_flash_fpga.TestFlashingProcess" name="test_flash_process_success" time="0.002"><failure message="AssertionError: assert '[flash]' in ''&#10; +  where '' = CaptureResult(out='', err='').out">tests/test_flash_fpga.py:141: in test_flash_process_success
    assert "[flash]" in captured.out
E   AssertionError: assert '[flash]' in ''
E    +  where '' = CaptureResult(out='', err='').out</failure></testcase><testcase classname="tests.test_flash_fpga.TestFlashingProcess" name="test_flash_process_no_usbloader" time="0.001" /><testcase classname="tests.test_flash_fpga.TestFlashingProcess" name="test_flash_process_no_bitfile" time="0.001" /><testcase classname="tests.test_flash_fpga.TestVIDPIDConfiguration" name="test_default_vidpid" time="0.001" /><testcase classname="tests.test_flash_fpga.TestVIDPIDConfiguration" name="test_flash_command_format" time="0.001" /><testcase classname="tests.test_flash_fpga.TestErrorHandling" name="test_usbloader_command_failure" time="0.001" /><testcase classname="tests.test_flash_fpga.TestErrorHandling" name="test_usbloader_permission_error" time="0.001" /><testcase classname="tests.test_flash_fpga.TestErrorHandling" name="test_invalid_bitfile_path" time="0.001" /><testcase classname="tests.test_flash_fpga.TestIntegrationScenarios" name="test_complete_flash_workflow" time="0.003" /><testcase classname="tests.test_flash_fpga.TestIntegrationScenarios" name="test_flash_with_different_boards" time="0.001" /><testcase classname="tests.test_flash_fpga.TestPerformanceAndReliability" name="test_large_firmware_file_handling" time="0.004" /><testcase classname="tests.test_flash_fpga.TestPerformanceAndReliability" name="test_concurrent_flash_attempts" time="0.001" /><testcase classname="tests.test_flash_fpga.TestPerformanceAndReliability" name="test_path_resolution_edge_cases" time="0.001" /><testcase classname="tests.test_flash_fpga.TestSecurityConsiderations" name="test_command_injection_prevention" time="0.001" /><testcase classname="tests.test_flash_fpga.TestSecurityConsiderations" name="test_safe_command_execution" time="0.001" /><testcase classname="tests.test_flash_fpga.TestSecurityConsiderations" name="test_file_permission_checks" time="0.001" /><testcase classname="tests.test_flash_fpga.TestDocumentationAndUsage" name="test_help_message_content" time="0.001" /><testcase classname="tests.test_flash_fpga.TestDocumentationAndUsage" name="test_usage_examples" time="0.001" /><testcase classname="tests.test_flash_fpga.TestDocumentationAndUsage" name="test_error_message_clarity" time="0.001"><failure message="AssertionError: assert ('Install it and retry' in 'usbloader not found' or 'usbloader not found' in 'Install it and retry')">tests/test_flash_fpga.py:456: in test_error_message_clarity
    assert expected_content in error_type or error_type in expected_content
E   AssertionError: assert ('Install it and retry' in 'usbloader not found' or 'usbloader not found' in 'Install it and retry')</failure></testcase><testcase classname="tests.test_flash_fpga.TestCompatibility" name="test_usbloader_path_variations" time="0.001" /><testcase classname="tests.test_flash_fpga.TestCompatibility" name="test_cross_platform_path_handling" time="0.001" /><testcase classname="tests.test_flash_fpga.TestCompatibility" name="test_filename_encoding_handling" time="0.001" /><testcase classname="tests.test_generate.TestBDFValidation" name="test_valid_bdf_formats" time="0.001" /><testcase classname="tests.test_generate.TestBDFValidation" name="test_invalid_bdf_formats" time="0.001" /><testcase classname="tests.test_generate.TestPCIDeviceEnumeration" name="test_list_pci_devices_success" time="0.002" /><testcase classname="tests.test_generate.TestPCIDeviceEnumeration" name="test_list_pci_devices_empty" time="0.001" /><testcase classname="tests.test_generate.TestPCIDeviceEnumeration" name="test_list_pci_devices_malformed" time="0.001" /><testcase classname="tests.test_generate.TestDeviceSelection" name="test_choose_device_valid_selection" time="0.001" /><testcase classname="tests.test_generate.TestDeviceSelection" name="test_choose_device_invalid_then_valid" time="0.001" /><testcase classname="tests.test_generate.TestDriverManagement" name="test_get_current_driver_exists" time="0.001" /><testcase classname="tests.test_generate.TestDriverManagement" name="test_get_current_driver_none" time="0.001" /><testcase classname="tests.test_generate.TestDriverManagement" name="test_get_current_driver_invalid_bdf" time="0.001" /><testcase classname="tests.test_generate.TestDriverManagement" name="test_get_iommu_group" time="0.001" /><testcase classname="tests.test_generate.TestDriverManagement" name="test_get_iommu_group_invalid_bdf" time="0.001" /><testcase classname="tests.test_generate.TestVFIOBinding" name="test_bind_to_vfio_success" time="0.001" /><testcase classname="tests.test_generate.TestVFIOBinding" name="test_bind_to_vfio_no_original_driver" time="0.001" /><testcase classname="tests.test_generate.TestVFIOBinding" name="test_bind_to_vfio_driver_not_available" time="0.001" /><testcase classname="tests.test_generate.TestVFIOBinding" name="test_bind_to_vfio_invalid_bdf" time="0.001" /><testcase classname="tests.test_generate.TestDriverRestore" name="test_restore_original_driver_success" time="0.001" /><testcase classname="tests.test_generate.TestDriverRestore" name="test_restore_original_driver_not_vfio" time="0.005" /><testcase classname="tests.test_generate.TestDriverRestore" name="test_restore_original_driver_no_original" time="0.015" /><testcase classname="tests.test_generate.TestUSBDeviceManagement" name="test_list_usb_devices_success" time="0.122"><failure message="AssertionError: assert ('1d50:6130',...nMoko, Inc. ') == ('1d50:6130',...enMoko, Inc.')&#10;  &#10;  At index 1 diff: #x1B[0m#x1B[33m'#x1B[39;49;00m#x1B[33mOpenMoko, Inc. #x1B[39;49;00m#x1B[33m'#x1B[39;49;00m#x1B[90m#x1B[39;49;00m != #x1B[0m#x1B[33m'#x1B[39;49;00m#x1B[33mOpenMoko, Inc.#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m#x1B[90m#x1B[39;49;00m&#10;  &#10;  Full diff:&#10;  #x1B[0m#x1B[90m #x1B[39;49;00m (#x1B[90m#x1B[39;49;00m&#10;  #x1B[90m #x1B[39;49;00m     '1d50:6130',#x1B[90m#x1B[39;49;00m&#10;  #x1B[91m-     'OpenMoko, Inc.',#x1B[39;49;00m#x1B[90m#x1B[39;49;00m...&#10;  &#10;  ...Full output truncated (3 lines hidden), use '-vv' to show">tests/test_generate.py:261: in test_list_usb_devices_success
    assert devices[0] == ("1d50:6130", "OpenMoko, Inc.")
E   AssertionError: assert ('1d50:6130',...nMoko, Inc. ') == ('1d50:6130',...enMoko, Inc.')
E     
E     At index 1 diff: #x1B[0m#x1B[33m'#x1B[39;49;00m#x1B[33mOpenMoko, Inc. #x1B[39;49;00m#x1B[33m'#x1B[39;49;00m#x1B[90m#x1B[39;49;00m != #x1B[0m#x1B[33m'#x1B[39;49;00m#x1B[33mOpenMoko, Inc.#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m#x1B[90m#x1B[39;49;00m
E     
E     Full diff:
E     #x1B[0m#x1B[90m #x1B[39;49;00m (#x1B[90m#x1B[39;49;00m
E     #x1B[90m #x1B[39;49;00m     '1d50:6130',#x1B[90m#x1B[39;49;00m
E     #x1B[91m-     'OpenMoko, Inc.',#x1B[39;49;00m#x1B[90m#x1B[39;49;00m...
E     
E     ...Full output truncated (3 lines hidden), use '-vv' to show</failure></testcase><testcase classname="tests.test_generate.TestUSBDeviceManagement" name="test_list_usb_devices_command_error" time="0.003" /><testcase classname="tests.test_generate.TestUSBDeviceManagement" name="test_select_usb_device_success" time="0.003" /><testcase classname="tests.test_generate.TestUSBDeviceManagement" name="test_select_usb_device_no_devices" time="0.005" /><testcase classname="tests.test_generate.TestFirmwareFlashing" name="test_flash_firmware_success" time="0.001" /><testcase classname="tests.test_generate.TestFirmwareFlashing" name="test_flash_firmware_no_usbloader" time="0.002" /><testcase classname="tests.test_generate.TestFirmwareFlashing" name="test_flash_firmware_command_failure" time="0.002" /><testcase classname="tests.test_generate.TestContainerExecution" name="test_run_build_container_success" time="0.002" /><testcase classname="tests.test_generate.TestContainerExecution" name="test_run_build_container_no_vfio_device" time="0.002" /><testcase classname="tests.test_generate.TestContainerExecution" name="test_run_build_container_invalid_bdf" time="0.001" /><testcase classname="tests.test_generate.TestContainerExecution" name="test_run_build_container_with_advanced_features" time="0.001" /><testcase classname="tests.test_generate.TestEnvironmentValidation" name="test_validate_environment_success" time="0.001" /><testcase classname="tests.test_generate.TestEnvironmentValidation" name="test_validate_environment_not_root" time="0.001" /><testcase classname="tests.test_generate.TestEnvironmentValidation" name="test_validate_environment_no_podman" time="0.001" /><testcase classname="tests.test_generate.TestMainWorkflow" name="test_main_success_no_flash" time="0.004"><failure message="AssertionError: expected call not found.&#10;Expected: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15')&#10;  Actual: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15', Namespace(tui=False, flash=False, board='75t', advanced_sv=False, device_type='generic', enable_variance=False, disable_power_management=False, disable_error_handling=False, disable_performance_counters=False, behavior_profile_duration=30))&#10;&#10;pytest introspection follows:&#10;&#10;Args:&#10;assert ('0000:03:00...._duration=30)) == ('0000:03:00..../dev/vfio/15')&#10;  &#10;  Left contains one more item: #x1B[0mNamespace(tui=#x1B[94mFalse#x1B[39;49;00m, flash=#x1B[94mFalse#x1B[39;49;00m, board=#x1B[33m'#x1B[39;49;00m#x1B[33m75t#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, advanced_sv=#x1B[94mFalse#x1B[39;49;00m, device_type=#x1B[33m'#x1B[39;49;00m#x1B[33mgeneric#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, enable_variance=#x1B[94mFalse#x1B[39;49;00m, disable_power_management=#x1B[94mFalse#x1B[39;49;00m, disable_error_handling=#x1B[94mFalse#x1B[39;49;00m, disable_performance_counters=#x1B[94mFalse#x1B[39;49;00m, behavior_profile_duration=#x1B[94m30#x1B[39;49;00m)#x1B[90m#x1B[39;49;00m&#10;  &#10;  Full diff:&#10;  #x1B[0m#x1B[90m #x1B[39;49;00m (#x1B[90m#x1B[39;49;00m&#10;  #x1B[90m #x1B[39;49;0...&#10;  &#10;  ...Full output truncated (5 lines hidden), use '-vv' to show">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:977: in assert_called_with
    raise AssertionError(_error_message()) from cause
E   AssertionError: expected call not found.
E   Expected: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15')
E     Actual: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15', Namespace(tui=False, flash=False, board='75t', advanced_sv=False, device_type='generic', enable_variance=False, disable_power_management=False, disable_error_handling=False, disable_performance_counters=False, behavior_profile_duration=30))

During handling of the above exception, another exception occurred:
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:989: in assert_called_once_with
    return self.assert_called_with(*args, **kwargs)
E   AssertionError: expected call not found.
E   Expected: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15')
E     Actual: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15', Namespace(tui=False, flash=False, board='75t', advanced_sv=False, device_type='generic', enable_variance=False, disable_power_management=False, disable_error_handling=False, disable_performance_counters=False, behavior_profile_duration=30))
E   
E   pytest introspection follows:
E   
E   Args:
E   assert ('0000:03:00...._duration=30)) == ('0000:03:00..../dev/vfio/15')
E     
E     Left contains one more item: #x1B[0mNamespace(tui=#x1B[94mFalse#x1B[39;49;00m, flash=#x1B[94mFalse#x1B[39;49;00m, board=#x1B[33m'#x1B[39;49;00m#x1B[33m75t#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, advanced_sv=#x1B[94mFalse#x1B[39;49;00m, device_type=#x1B[33m'#x1B[39;49;00m#x1B[33mgeneric#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, enable_variance=#x1B[94mFalse#x1B[39;49;00m, disable_power_management=#x1B[94mFalse#x1B[39;49;00m, disable_error_handling=#x1B[94mFalse#x1B[39;49;00m, disable_performance_counters=#x1B[94mFalse#x1B[39;49;00m, behavior_profile_duration=#x1B[94m30#x1B[39;49;00m)#x1B[90m#x1B[39;49;00m
E     
E     Full diff:
E     #x1B[0m#x1B[90m #x1B[39;49;00m (#x1B[90m#x1B[39;49;00m
E     #x1B[90m #x1B[39;49;0...
E     
E     ...Full output truncated (5 lines hidden), use '-vv' to show

During handling of the above exception, another exception occurred:
tests/test_generate.py:516: in test_main_success_no_flash
    mock_container.assert_called_once_with("0000:03:00.0", "75t", "/dev/vfio/15")
E   AssertionError: expected call not found.
E   Expected: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15')
E     Actual: run_build_container('0000:03:00.0', '75t', '/dev/vfio/15', Namespace(tui=False, flash=False, board='75t', advanced_sv=False, device_type='generic', enable_variance=False, disable_power_management=False, disable_error_handling=False, disable_performance_counters=False, behavior_profile_duration=30))
E   
E   pytest introspection follows:
E   
E   Args:
E   assert ('0000:03:00...._duration=30)) == ('0000:03:00..../dev/vfio/15')
E     
E     Left contains one more item: #x1B[0mNamespace(tui=#x1B[94mFalse#x1B[39;49;00m, flash=#x1B[94mFalse#x1B[39;49;00m, board=#x1B[33m'#x1B[39;49;00m#x1B[33m75t#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, advanced_sv=#x1B[94mFalse#x1B[39;49;00m, device_type=#x1B[33m'#x1B[39;49;00m#x1B[33mgeneric#x1B[39;49;00m#x1B[33m'#x1B[39;49;00m, enable_variance=#x1B[94mFalse#x1B[39;49;00m, disable_power_management=#x1B[94mFalse#x1B[39;49;00m, disable_error_handling=#x1B[94mFalse#x1B[39;49;00m, disable_performance_counters=#x1B[94mFalse#x1B[39;49;00m, behavior_profile_duration=#x1B[94m30#x1B[39;49;00m)#x1B[90m#x1B[39;49;00m
E     
E     Full diff:
E     #x1B[0m#x1B[90m #x1B[39;49;00m (#x1B[90m#x1B[39;49;00m
E     #x1B[90m #x1B[39;49;0...
E     
E     ...Full output truncated (5 lines hidden), use '-vv' to show</failure></testcase><testcase classname="tests.test_generate.TestMainWorkflow" name="test_main_success_with_flash" time="0.002" /><testcase classname="tests.test_generate.TestMainWorkflow" name="test_main_no_devices" time="0.001" /><testcase classname="tests.test_generate.TestMainWorkflow" name="test_main_keyboard_interrupt" time="0.001" /><testcase classname="tests.test_generate.TestErrorHandling" name="test_run_command_success" time="0.001" /><testcase classname="tests.test_generate.TestErrorHandling" name="test_run_command_failure" time="0.001" /><testcase classname="tests.test_generate.TestArgumentParsing" name="test_default_arguments" time="0.001" /><testcase classname="tests.test_generate.TestArgumentParsing" name="test_custom_arguments" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_simulator_initialization" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_variance_model_generation" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_device_class_parameters" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_timing_pattern_analysis" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_variance_application" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_systemverilog_code_generation" time="0.002"><failure message="assert 'variance-aware' in &quot;\n    // Variance-aware timing for test_reg\n    // Device class: consumer\n    // Base cycles: 5, Adjusted: 6\n    // Jitter range: ±2 cycles\n    logic [3:0] test_reg_delay_counter = 0;\n    logic [1:0] test_reg_jitter_lfsr = 1; // LFSR for jitter\n    logic test_reg_write_pending = 0;\n    \n    // LFSR for timing jitter generation\n    always_ff @(posedge clk) begin\n        if (!reset_n) begin\n            test_reg_jitter_lfsr &lt;= 1;\n        end else begin\n            // Simple LFSR for pseudo-random jitter\n            test_reg_jitter_lfsr &lt;= {test_reg_jitter_lfsr[0:0], \n                                            test_reg_jitter_lfsr[1] ^ \n                                            test_reg_jitter_lfsr[0]};\n        end\n    end\n    \n    // Variance-aware timing logic\n    always_ff @(posedge clk) begin\n        if (!reset_n) begin\n            test_reg_delay_counter &lt;= 0;\n            test_reg_write_pending &lt;= 0;\n        end else if (bar_wr_en &amp;&amp; bar_addr == 32'h00000400) begin\n            test_reg_write_pending &lt;= 1;\n            // Apply base delay with manufacturing variance\n            test_reg_delay_counter &lt;= 6 +\n                                           (test_reg_jitter_lfsr % 3);\n        end else if (test_reg_write_pending &amp;&amp; test_reg_delay_counter &gt; 0) begin\n            test_reg_delay_counter &lt;= test_reg_delay_counter - 1;\n        end else if (test_reg_write_pending &amp;&amp; test_reg_delay_counter == 0) begin\n            test_reg_reg &lt;= bar_wr_data;\n            test_reg_write_pending &lt;= 0;\n        end\n    end&quot;">tests/test_manufacturing_variance.py:118: in test_systemverilog_code_generation
    assert "variance-aware" in sv_code
E   assert 'variance-aware' in "\n    // Variance-aware timing for test_reg\n    // Device class: consumer\n    // Base cycles: 5, Adjusted: 6\n    // Jitter range: ±2 cycles\n    logic [3:0] test_reg_delay_counter = 0;\n    logic [1:0] test_reg_jitter_lfsr = 1; // LFSR for jitter\n    logic test_reg_write_pending = 0;\n    \n    // LFSR for timing jitter generation\n    always_ff @(posedge clk) begin\n        if (!reset_n) begin\n            test_reg_jitter_lfsr &lt;= 1;\n        end else begin\n            // Simple LFSR for pseudo-random jitter\n            test_reg_jitter_lfsr &lt;= {test_reg_jitter_lfsr[0:0], \n                                            test_reg_jitter_lfsr[1] ^ \n                                            test_reg_jitter_lfsr[0]};\n        end\n    end\n    \n    // Variance-aware timing logic\n    always_ff @(posedge clk) begin\n        if (!reset_n) begin\n            test_reg_delay_counter &lt;= 0;\n            test_reg_write_pending &lt;= 0;\n        end else if (bar_wr_en &amp;&amp; bar_addr == 32'h00000400) begin\n            test_reg_write_pending &lt;= 1;\n            // Apply base delay with manufacturing variance\n            test_reg_delay_counter &lt;= 6 +\n                                           (test_reg_jitter_lfsr % 3);\n        end else if (test_reg_write_pending &amp;&amp; test_reg_delay_counter &gt; 0) begin\n            test_reg_delay_counter &lt;= test_reg_delay_counter - 1;\n        end else if (test_reg_write_pending &amp;&amp; test_reg_delay_counter == 0) begin\n            test_reg_reg &lt;= bar_wr_data;\n            test_reg_write_pending &lt;= 0;\n        end\n    end"</failure></testcase><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_variance_metadata" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_variance_parameters_dataclass" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_variance_model_timing_calculations" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestManufacturingVarianceSimulator" name="test_reproducible_generation" time="0.001"><failure message="AssertionError: assert 3.2094543954037773 == 6.408346475717474&#10; +  where 3.2094543954037773 = VarianceModel(device_id='test', device_class=&lt;DeviceClass.CONSUMER: 'consumer'&gt;, base_frequency_mhz=100.0, clock_jitter_percent=3.2094543954037773, register_timing_jitter_ns=25.231200651357938, power_noise_percent=3.221725291011195, temperature_drift_ppm_per_c=19.693021144459514, process_variation_percent=18.814386535420336, propagation_delay_ps=55.72304991534836, operating_temp_c=45.57717340288379, supply_voltage_v=3.244625240508194, timing_adjustments={'base_period_ns': 10.0, 'jitter_ns': 0.32094543954037774, 'register_access_jitter_ns': 25.231200651357938, 'temp_factor': 1.0004052267109163, 'process_factor': 1.1881438653542034, 'power_factor': 1.032217252910112, 'propagation_delay_ps': 55.72304991534836, 'combined_timing_factor': 1.2269195759529952}).clock_jitter_percent&#10; +  and   6.408346475717474 = VarianceModel(device_id='test', device_class=&lt;DeviceClass.CONSUMER: 'consumer'&gt;, base_frequency_mhz=100.0, clock_jitter_percent=6.408346475717474, register_timing_jitter_ns=29.579743803318195, power_noise_percent=3.0116499713278264, temperature_drift_ppm_per_c=40.04167551660598, process_variation_percent=10.941960230211333, propagation_delay_ps=50.25058303688343, operating_temp_c=37.08344244029356, supply_voltage_v=3.1639124549176394, timing_adjustments={'base_period_ns': 10.0, 'jitter_ns': 0.6408346475717475, 'register_access_jitter_ns': 29.579743803318195, 'temp_factor': 1.0004838412813177, 'process_factor': 1.1094196023021132, 'power_factor': 1.0301164997132783, 'propagation_delay_ps': 50.25058303688343, 'combined_timing_factor': 1.1433843864637698}).clock_jitter_percent">tests/test_manufacturing_variance.py:187: in test_reproducible_generation
    assert model1.clock_jitter_percent == model2.clock_jitter_percent
E   AssertionError: assert 3.2094543954037773 == 6.408346475717474
E    +  where 3.2094543954037773 = VarianceModel(device_id='test', device_class=&lt;DeviceClass.CONSUMER: 'consumer'&gt;, base_frequency_mhz=100.0, clock_jitter_percent=3.2094543954037773, register_timing_jitter_ns=25.231200651357938, power_noise_percent=3.221725291011195, temperature_drift_ppm_per_c=19.693021144459514, process_variation_percent=18.814386535420336, propagation_delay_ps=55.72304991534836, operating_temp_c=45.57717340288379, supply_voltage_v=3.244625240508194, timing_adjustments={'base_period_ns': 10.0, 'jitter_ns': 0.32094543954037774, 'register_access_jitter_ns': 25.231200651357938, 'temp_factor': 1.0004052267109163, 'process_factor': 1.1881438653542034, 'power_factor': 1.032217252910112, 'propagation_delay_ps': 55.72304991534836, 'combined_timing_factor': 1.2269195759529952}).clock_jitter_percent
E    +  and   6.408346475717474 = VarianceModel(device_id='test', device_class=&lt;DeviceClass.CONSUMER: 'consumer'&gt;, base_frequency_mhz=100.0, clock_jitter_percent=6.408346475717474, register_timing_jitter_ns=29.579743803318195, power_noise_percent=3.0116499713278264, temperature_drift_ppm_per_c=40.04167551660598, process_variation_percent=10.941960230211333, propagation_delay_ps=50.25058303688343, operating_temp_c=37.08344244029356, supply_voltage_v=3.1639124549176394, timing_adjustments={'base_period_ns': 10.0, 'jitter_ns': 0.6408346475717475, 'register_access_jitter_ns': 29.579743803318195, 'temp_factor': 1.0004838412813177, 'process_factor': 1.1094196023021132, 'power_factor': 1.0301164997132783, 'propagation_delay_ps': 50.25058303688343, 'combined_timing_factor': 1.1433843864637698}).clock_jitter_percent</failure></testcase><testcase classname="tests.test_manufacturing_variance.TestVarianceIntegration" name="test_default_device_class_parameters" time="0.001" /><testcase classname="tests.test_manufacturing_variance.TestVarianceIntegration" name="test_variance_ranges_logical" time="0.001" /><testcase classname="tests.test_sv_validation.TestSystemVerilogValidation" name="test_sv_module_structure_matches_example" time="0.002" /><testcase classname="tests.test_sv_validation.TestSystemVerilogValidation" name="test_sv_register_handling_matches_example" time="0.001" /><testcase classname="tests.test_sv_validation.TestSystemVerilogValidation" name="test_sv_clock_domain_handling" time="0.001" /><testcase classname="tests.test_sv_validation.TestSystemVerilogValidation" name="test_sv_interface_compatibility" time="0.002" /><testcase classname="tests.test_sv_validation.TestSystemVerilogValidation" name="test_sv_error_handling_compatibility" time="0.001" /><testcase classname="tests.test_sv_validation.TestAdvancedSVFeatureValidation" name="test_state_machine_generation" time="0.001" /><testcase classname="tests.test_sv_validation.TestAdvancedSVFeatureValidation" name="test_memory_interface_compatibility" time="0.001" /><testcase classname="tests.test_tcl_validation.TestTCLValidation" name="test_tcl_structure_matches_example" time="0.002" /><testcase classname="tests.test_tcl_validation.TestTCLValidation" name="test_tcl_device_id_configuration" time="0.003" /><testcase classname="tests.test_tcl_validation.TestTCLValidation" name="test_tcl_bar_size_configuration" time="0.002" /><testcase classname="tests.test_tcl_validation.TestTCLValidation" name="test_tcl_file_inclusion" time="0.002" /><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_device_manager_init" time="0.001" /><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_vendor_database_loading" time="0.001" /><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_scan_devices_success" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_scan_devices_failure" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_extract_device_name" time="0.001" /><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_assess_device_suitability" time="0.001"><failure message="AssertionError: assert 1 == 0&#10; +  where 1 = len(['Limited BAR configuration'])">tests/test_tui_core.py:136: in test_assess_device_suitability
    assert len(issues) == 0
E   AssertionError: assert 1 == 0
E    +  where 1 = len(['Limited BAR configuration'])</failure></testcase><testcase classname="tests.test_tui_core.TestDeviceManager" name="test_cached_operations" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_config_manager_init" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_current_config_management" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_create_default_profiles" time="0.002" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_save_and_load_profile" time="0.001"><failure message="AssertionError: assert False&#10; +  where False = exists()&#10; +    where exists = PosixPath('/var/folders/pz/zdq1ptxs0h3700ssftp1vlch0000gn/T/tmph38oeugk/Test_Profile.json').exists">tests/test_tui_core.py:264: in test_save_and_load_profile
    assert profile_file.exists()
E   AssertionError: assert False
E    +  where False = exists()
E    +    where exists = PosixPath('/var/folders/pz/zdq1ptxs0h3700ssftp1vlch0000gn/T/tmph38oeugk/Test_Profile.json').exists</failure></testcase><testcase classname="tests.test_tui_core.TestConfigManager" name="test_profile_operations" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_list_profiles" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_delete_profile" time="0.001" /><testcase classname="tests.test_tui_core.TestConfigManager" name="test_config_validation" time="0.001" /><testcase classname="tests.test_tui_core.TestBuildOrchestrator" name="test_build_orchestrator_init" time="0.001" /><testcase classname="tests.test_tui_core.TestBuildOrchestrator" name="test_progress_management" time="0.001" /><testcase classname="tests.test_tui_core.TestBuildOrchestrator" name="test_start_build_success" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestBuildOrchestrator" name="test_build_already_running" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestBuildOrchestrator" name="test_cancel_build" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_status_monitor_init" time="0.001" /><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_check_podman_status" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_check_vivado_status" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_get_disk_space" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_check_root_access" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_get_system_status" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_monitoring_control" time="0.001" /><testcase classname="tests.test_tui_core.TestStatusMonitor" name="test_status_summary" time="0.001" /><testcase classname="tests.test_tui_main.TestConfigurationDialog" name="test_configuration_dialog_init" time="0.001" /><testcase classname="tests.test_tui_main.TestConfigurationDialog" name="test_create_config_from_form" time="0.002" /><testcase classname="tests.test_tui_main.TestConfigurationDialog" name="test_populate_form" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_tui_app_init" time="0.009" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_app_properties" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_initialize_app" time="0.003"><failure message="textual.app.ScreenStackError: No screens on stack">tests/test_tui_main.py:178: in test_initialize_app
    await app._initialize_app()
src/tui/main.py:337: in _initialize_app
    self._update_config_display()
src/tui/main.py:372: in _update_config_display
    self.query_one("#board-type", Static).update(f"Board Type: {config.board_type}")
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/dom.py:1465: in query_one
    base_node = self._get_dom_base()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:870: in _get_dom_base
    return self.default_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:883: in default_screen
    return self.screen if self._compose_screen is None else self._compose_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:1472: in screen
    raise ScreenStackError("No screens on stack") from None
E   textual.app.ScreenStackError: No screens on stack</failure></testcase><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_scan_devices" time="0.003" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_update_device_table" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_update_config_display" time="0.004" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_update_status_display" time="0.003" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_update_build_progress" time="0.002"><failure message="textual.app.ScreenStackError: No screens on stack">tests/test_tui_main.py:337: in test_update_build_progress
    app.build_progress = BuildProgress(
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/reactive.py:345: in __set__
    self._set(obj, value)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/reactive.py:326: in _set
    self._check_watchers(obj, name, current_value)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/reactive.py:367: in _check_watchers
    invoke_watcher(obj, public_watch_function, old_value, value)
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/reactive.py:91: in invoke_watcher
    watch_result = cast(WatchCallbackNewValueType, watch_function)(value)
src/tui/main.py:573: in watch_build_progress
    self._update_build_progress()
src/tui/main.py:441: in _update_build_progress
    self.query_one("#build-status", Static).update(
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/dom.py:1465: in query_one
    base_node = self._get_dom_base()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:870: in _get_dom_base
    return self.default_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:883: in default_screen
    return self.screen if self._compose_screen is None else self._compose_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:1472: in screen
    raise ScreenStackError("No screens on stack") from None
E   textual.app.ScreenStackError: No screens on stack</failure></testcase><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_button_press_handlers" time="0.003" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_data_table_row_selection" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_start_build" time="0.003"><failure message="textual.app.ScreenStackError: No screens on stack">tests/test_tui_main.py:478: in test_start_build
    await app._start_build()
src/tui/main.py:537: in _start_build
    self.query_one("#start-build", Button).disabled = False
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/dom.py:1465: in query_one
    base_node = self._get_dom_base()
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:870: in _get_dom_base
    return self.default_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:883: in default_screen
    return self.screen if self._compose_screen is None else self._compose_screen
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/textual/app.py:1472: in screen
    raise ScreenStackError("No screens on stack") from None
E   textual.app.ScreenStackError: No screens on stack</failure></testcase><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_stop_build" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_build_progress_callback" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_reactive_watchers" time="0.002"><failure message="AssertionError: assert &lt;MagicMock name='mock.disabled' id='4363128176'&gt; is False&#10; +  where &lt;MagicMock name='mock.disabled' id='4363128176'&gt; = &lt;MagicMock id='4363133216'&gt;.disabled">tests/test_tui_main.py:554: in test_reactive_watchers
    assert mock_buttons["#start-build"].disabled is False
E   AssertionError: assert &lt;MagicMock name='mock.disabled' id='4363128176'&gt; is False
E    +  where &lt;MagicMock name='mock.disabled' id='4363128176'&gt; = &lt;MagicMock id='4363133216'&gt;.disabled</failure></testcase><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_build_progress_watcher" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_open_configuration_dialog" time="0.002" /><testcase classname="tests.test_tui_main.TestPCILeechTUI" name="test_monitor_system_status" time="0.002" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_default_configuration" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_configuration_validation" time="0.002" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_is_advanced_property" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_feature_summary" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_to_cli_args" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_serialization" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_file_operations" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildConfiguration" name="test_copy" time="0.001" /><testcase classname="tests.test_tui_models.TestPCIDevice" name="test_device_creation" time="0.001" /><testcase classname="tests.test_tui_models.TestPCIDevice" name="test_display_name" time="0.001" /><testcase classname="tests.test_tui_models.TestPCIDevice" name="test_is_suitable" time="0.001" /><testcase classname="tests.test_tui_models.TestPCIDevice" name="test_status_indicator" time="0.001" /><testcase classname="tests.test_tui_models.TestPCIDevice" name="test_serialization" time="0.001" /><testcase classname="tests.test_tui_models.TestTUIError" name="test_error_creation" time="0.001" /><testcase classname="tests.test_tui_models.TestTUIError" name="test_severity_properties" time="0.001" /><testcase classname="tests.test_tui_models.TestTUIError" name="test_add_action" time="0.001" /><testcase classname="tests.test_tui_models.TestTUIError" name="test_serialization" time="0.001" /><testcase classname="tests.test_tui_models.TestErrorTemplates" name="test_vfio_binding_failed" time="0.001" /><testcase classname="tests.test_tui_models.TestErrorTemplates" name="test_container_not_found" time="0.001" /><testcase classname="tests.test_tui_models.TestErrorTemplates" name="test_insufficient_permissions" time="0.001" /><testcase classname="tests.test_tui_models.TestErrorTemplates" name="test_build_failed" time="0.001" /><testcase classname="tests.test_tui_models.TestErrorTemplates" name="test_device_not_suitable" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_progress_creation" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_stage_tracking" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_overall_progress" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_status_text" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_progress_bar_text" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_warning_and_error_management" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_resource_usage_update" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildProgress" name="test_serialization" time="0.001" /><testcase classname="tests.test_tui_models.TestBuildStage" name="test_build_stages" time="0.001" /></testsuite></testsuites>